{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are in possession of labelled data, we can take a\n",
    "step further and use those labels in a supervised learning\n",
    "task, where the labels become our targets. In this chapter we\n",
    "will discuss how classification algorithms are used and\n",
    "scored. In particular we will cover some important\n",
    "algorithms such as K Nearest Neighbours, Logistic\n",
    "Regression and the famous Naïve Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is a task that involves arranging\n",
    "objects systematically into appropriate groups or categories\n",
    "depending on the characteristics that define such groupings.\n",
    "It is important to emphasise that the groups are pre-defined\n",
    "according to established criteria. In our case, the use of classification is to determine the category to which an\n",
    "unseen observation belongs, depending on the information\n",
    "of a training dataset with appropriate labels. Classification\n",
    "is therefore a supervised learning task. Whereas in clustering\n",
    "the aim is to determine the groups from the features in the\n",
    "dataset, classification uses the labelled groups to predict\n",
    "the best category for unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very convenient way to evaluate the accuracy of a\n",
    "classifier is the use of a table that summarises the\n",
    "performance of our algorithm against the data provided.\n",
    "Karl Pearson used the name contingency table. The machine learning community tends to call it a confusion\n",
    "matrix as it lets us determine if the classifier is confusing\n",
    "two classes by assigning observations of one class to the\n",
    "other. One advantage of a confusion matrix is that it can be\n",
    "extended to cases with more than two categories. In any case, the contingency table or confusion matrix is\n",
    "organised in such a way that its columns are related to the\n",
    "instances in a predicted category, whereas its rows refer to\n",
    "actual classes. A False Positive is a case where we have incorrectly made\n",
    "a prediction for a positive detection. From the table we can see that the troop has predicted 6 cases as aircraft,\n",
    "but they turned out to be flocks. Finally, a False Negative\n",
    "is a case where we have incorrectly made a prediction\n",
    "for a negative detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall or True Positive Rate (TPR) : It is also known as sensitivity\n",
    "or hit rate. It corresponds to the proportion of positive data points that are correctly classified as positive versus the total\n",
    "number of positive points. The true positive rate is also known as recall or sensitivity (TP/TP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Negative Rate or Specificity (TNR): It is the counterpart\n",
    "of the True Positive Rate as it measures the proportion of negatives that have been correctly identified. The true negative rate is also\n",
    "known as specificity (TN/TN+FP) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fallout or False Positive Rate (FPR): It corresponds to the\n",
    "proportion of negative data points that are mistakenly considered as positive, with respect to all negative data\n",
    "points. The false positive rate is also\n",
    "known as fallout.(1-TNR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision or Postitive Predictive Value (PPV): It is the proportion\n",
    "of positive results that are true positive results. The precision is also known as\n",
    "positive predictive value.(TP/TP+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is given by the ratio of the points that\n",
    "have been correctly classified and the total number of data\n",
    "points.(TP+TN)/(TP+FP+TN+FN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 AUC and ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Receiver Operator Characteristic or ROC is a\n",
    "quantitative analysis technique used in binary classification. It lets us construct a curve in terms of the true positive rate against the false positive rate. Unfortunately\n",
    "ROC curves are suitable for binary classification problems\n",
    "only. In a ROC curve the True Positive Rate is plotted as a function of the False Positive Rate for different cut-off\n",
    "points or thresholds for the classifier. Think of these\n",
    "thresholds as settings in the receiver used by the radar\n",
    "operators. If our classifier is able to distinguish the two classes without\n",
    "overlap, then the ROC would have a point at the 100% sensitivity and 0% fallout, i.e. the upper left corner of the curve. This means that the closer the ROC curve is to that corner, then the better the accuracy of the classifier. It\n",
    "is clear that we would prefer classifiers that are better than guessing, in other words those whose ROC curve lies above\n",
    "the diagonal. Also we would prefer those classifiers whose\n",
    "ROC curves are closer to the curve given by the perfect\n",
    "classifier. If you end up with a ROC curve that lies below\n",
    "the diagonal, your classifier is worse than guessing, and it should be immediately discarded. AUC is the Area Under the ROC curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Classification with KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the KNN classifier, similarity is given by the distance\n",
    "between points. We classify new observations taking into account the class of the k nearest labelled data points. This means that we need a distance measure between points, and we can start with the well-known Euclidean distance we\n",
    "discussed in Section 3.8. As it was the case in k-means for clustering, the value of k in KNN is a parameter that is given as an input to the algorithm. For a new unseen observation, we measure the\n",
    "distance to the rest of the points in the dataset and pick the\n",
    "k nearest points. We then simply take the most common\n",
    "class among these to be the class of the new observation. In\n",
    "terms of steps we have the following: 1. Choose a value for k as an input. 2. Select the k nearest data points to the new observation. 3. Find the most common class among the k points chosen. 4. Assign this class to the new observation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as ms\n",
    "XTrain,XTest,YTrain,YTest = ms.train_test_split(X,Y,test_size=0.3,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=False),\n       error_score='raise-deprecating',\n       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n           weights='uniform'),\n       fit_params=None, iid='warn', n_jobs=None,\n       param_grid=[{'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]}],\n       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n       scoring=None, verbose=0)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Find the appropriate value of \"k\" using gridsearch\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# search between 1 and 20 and find best value of k using cross-validation\n",
    "k_neighbours = list(range(1,21,2))\n",
    "n_grid = [{'n_neighbors':k_neighbours}]\n",
    "# apply result to classifier function\n",
    "model = neighbors.KNeighborsClassifier()\n",
    "cv_knn = GridSearchCV(estimator=model,param_grid=n_grid,cv=ms.KFold(n_splits=10))\n",
    "cv_knn.fit(XTrain,YTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "11\n"
    }
   ],
   "source": [
    "# Model results (best k)\n",
    "best_k = cv_knn.best_params_['n_neighbors']\n",
    "print(best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n           weights='uniform')"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Train model with best k\n",
    "knnclf = neighbors.KNeighborsClassifier(n_neighbors=best_k)\n",
    "knnclf.fit(XTrain[:,2:4],YTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2, 1, 0, 1, 1, 0, 1, 1, 0, 1, 2, 1, 0, 2, 0, 2, 2, 2, 0, 0, 1, 2,\n       1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 0, 2, 1, 0, 0, 0, 0, 2, 2, 1, 2, 2,\n       1])"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred = knnclf.predict(XTest[:,2:4])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[12,  0,  0],\n       [ 0, 14,  2],\n       [ 0,  2, 15]])"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(YTest,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        12\n           1       0.88      0.88      0.88        16\n           2       0.88      0.88      0.88        17\n\n   micro avg       0.91      0.91      0.91        45\n   macro avg       0.92      0.92      0.92        45\nweighted avg       0.91      0.91      0.91        45\n\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(YTest,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Classification with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is used in the prediction of a discrete outcome\n",
    "and therefore best suited for classification purposes. Logistic\n",
    "regression is in effect another generalised linear model that\n",
    "uses the same basic background as linear regression.\n",
    "However, instead of a continuous dependent variable, the\n",
    "model is regressing for the probability of a (binary) categorical outcome. We can then use these probabilities to\n",
    "obtain class labels for our data observations. In logistic regression, we are interested in determining the\n",
    "probability that an observation belongs to a category (or not)\n",
    "and therefore the conditional mean of the outcome variable. We need to extend the linear regression model to map the outcome variable into that\n",
    "unit interval. In logistic regression, however, the outcome variable can\n",
    "take only two values: Either 0 or 1. This means that instead of following a Gaussian distribution it follows a Bernoulli\n",
    "one. The Bernoulli distribution corresponds to a random\n",
    "variable that takes the value 1 with probability p and 0 with\n",
    "probability q = 1 - p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = pd.read_csv('Data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0    842302         M        17.99         10.38          122.80     1001.0   \n1    842517         M        20.57         17.77          132.90     1326.0   \n2  84300903         M        19.69         21.25          130.00     1203.0   \n3  84348301         M        11.42         20.38           77.58      386.1   \n4  84358402         M        20.29         14.34          135.10     1297.0   \n\n   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0          0.11840           0.27760          0.3001              0.14710   \n1          0.08474           0.07864          0.0869              0.07017   \n2          0.10960           0.15990          0.1974              0.12790   \n3          0.14250           0.28390          0.2414              0.10520   \n4          0.10030           0.13280          0.1980              0.10430   \n\n   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n0  ...         25.38          17.33           184.60      2019.0   \n1  ...         24.99          23.41           158.80      1956.0   \n2  ...         23.57          25.53           152.50      1709.0   \n3  ...         14.91          26.50            98.87       567.7   \n4  ...         22.54          16.67           152.20      1575.0   \n\n   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n0            0.1622             0.6656           0.7119                0.2654   \n1            0.1238             0.1866           0.2416                0.1860   \n2            0.1444             0.4245           0.4504                0.2430   \n3            0.2098             0.8663           0.6869                0.2575   \n4            0.1374             0.2050           0.4000                0.1625   \n\n   symmetry_worst  fractal_dimension_worst  \n0          0.4601                  0.11890  \n1          0.2750                  0.08902  \n2          0.3613                  0.08758  \n3          0.6638                  0.17300  \n4          0.2364                  0.07678  \n\n[5 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "bc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bc = bc.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate labels\n",
    "X = bc.drop(['diagnosis'],axis=1)\n",
    "X = X.values\n",
    "Y_raw = bc['diagnosis'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to 0 and 1\n",
    "from sklearn import preprocessing\n",
    "label_enc = preprocessing.LabelEncoder()\n",
    "label_enc.fit(Y_raw)\n",
    "Y = label_enc.transform(Y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in train and test\n",
    "import sklearn.model_selection as cv\n",
    "XTrain,XTest,YTrain,YTest = ms.train_test_split(X,Y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use regularisation in the model and can choose between L1 and L2 penalties\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "pen_val = ['l1','l2']\n",
    "C_val = 2. ** np.arange(-5,10,step=2)\n",
    "grid_s = [{'C':C_val,'penalty':pen_val}]\n",
    "model = LogisticRegression()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "cv_logr = GridSearchCV(estimator=model,param_grid=grid_s,cv=ms.KFold(n_splits=10))\n",
    "# Model fitting\n",
    "cv_logr.fit(XTrain,YTrain)\n",
    "best_c = cv_logr.best_params_['C']\n",
    "best_penalty = cv_logr.best_params_['penalty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LogisticRegression(C=128.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l1', random_state=None, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "# Create an instance of the logistic regression model\n",
    "b_clf = LogisticRegression(C=best_c,penalty=best_penalty)\n",
    "b_clf.fit(XTrain,YTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9766081871345029\n"
    }
   ],
   "source": [
    "# Predict\n",
    "predict = b_clf.predict(XTest)\n",
    "y_proba = b_clf.predict_proba(XTest)\n",
    "print(b_clf.score(XTest,YTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 3.84883758e-09 -9.31267991e-01  1.47545778e-01 -1.21785996e-01\n  -2.72486306e-03  0.00000000e+00 -3.18103919e+01  1.26021393e+01\n   9.85393362e+01  0.00000000e+00  0.00000000e+00  4.33243499e-02\n  -1.86163550e-01 -6.15026172e-03  1.69921352e-01  0.00000000e+00\n  -6.68164161e+01 -1.94733922e+01  0.00000000e+00  0.00000000e+00\n   0.00000000e+00 -5.48167019e-02  2.55421229e-01  2.84395012e-02\n   2.35265717e-02  0.00000000e+00 -3.55547741e-01  5.83800329e+00\n   5.10734917e+01  2.04216303e+01  0.00000000e+00]]\n"
    }
   ],
   "source": [
    "# coefficients\n",
    "print(b_clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[1.00000000e+00 3.94053737e-01 1.15898634e+00 8.85337814e-01\n  9.97278846e-01 1.00000000e+00 1.53081368e-14 2.97193677e+05\n  6.23864074e+42 1.00000000e+00 1.00000000e+00 1.04427655e+00\n  8.30137815e-01 9.93868612e-01 1.18521163e+00 1.00000000e+00\n  9.59398863e-30 3.48990193e-09 1.00000000e+00 1.00000000e+00\n  1.00000000e+00 9.46658653e-01 1.29100532e+00 1.02884776e+00\n  1.02380550e+00 1.00000000e+00 7.00789487e-01 3.43093597e+02\n  1.51682554e+22 7.39607612e+08 1.00000000e+00]]\n"
    }
   ],
   "source": [
    "# odds rastio (exp of coefficients) -> how a unit increase or decrease in a variable affects the odds of having a malignant mass\n",
    "print(np.exp(b_clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9979423868312757\n"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve,auc\n",
    "import matplotlib.pyplot as plt\n",
    "fpr,tpr,threshold = roc_curve(YTest,y_proba[:,1])\n",
    "print(auc(fpr,tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}