{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We talk about clustering when the groups made out of\n",
    "similar data points do not have a predefined name or label.When the label does exist we talk about classification and\n",
    "will cover it in Chapter 6. Clustering analysis is an\n",
    "unsupervised machine learning task, whereas classification\n",
    "is a supervised one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cluster can be thought of as a group of similar\n",
    "data points and therefore the concept of similarity is at the\n",
    "heart of the definition of a cluster. The greater the similarity among points leads to better clustering and thus to better\n",
    "results. That its goal is to\n",
    "provide us with a better understanding of our dataset by\n",
    "dividing the data points into relevant groups. Clustering provides us with a\n",
    "layer of abstraction from individual data points to collections of them that share similar characteristics. It is\n",
    "important to clarify that the enhancement is made by\n",
    "extracting information from the inherent structure of the\n",
    "data itself, rather than imposing an arbitrary external one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Clustering with K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its goal is to partition an N-dimensional dataset into k different sets, whose number\n",
    "is fixed at the start of the process. The algorithm performs a\n",
    "complete clustering of the dataset, in other words, each data\n",
    "point considered will belong to exactly one of the k clusters.\n",
    "The most important part of the process\n",
    "is determining the partitions that form the k sets. This is\n",
    "done by defining k centroids and assigning each data point to the cluster with the nearest centroid. The centroid is then\n",
    "updated by taking the mean of the data points in the cluster.\n",
    "The partitions are not scale-invariant and therefore the same dataset may lead to very different results depending on the scale and units used.\n",
    "The initial k centroids are set at the beginning of the process and different locations may lead to different results.\n",
    "The general idea behind k-means can be summarised in the following four\n",
    "steps: Choose the location of the initial k centroids. For each data point, find the distance to each of the k\n",
    "centroids and assign the point to the nearest one. Once all data points have been assigned to a cluster,\n",
    "recalculate the centroid positions. Repeat steps 2 and 3 until convergence is met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Cluster Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that even in cases where no\n",
    "partion exists, k-means will return a partition of the dataset\n",
    "in to k subsets. It is therefore useful to validate the clusters obtained. Cluster validation can be further used to identify clusters that should be split or merged, or to identify individual points with disproportionate effect on the overall clustering. This can be done with the help of two measures: Cohesion and separation. Cohesion is a measure of how closely related data points within a cluster are, and is given by the\n",
    "within-cluster SSE. Separation is a measure of how well clusters are segregated from each other. The overal cohesion and\n",
    "separation measures are given by the sum over clusters; in the case of separation it is not unusual to weight each of the terms in the sum. An alternative measure of validity that provides us with a and separation.\n",
    "combination of the ideas behind cohesion and separation in\n",
    "a single coefficient is given by the silhouette score (from -1 to 1). The average silhouette over the entire\n",
    "dataset tells us how well the clustering algorithm has\n",
    "performed and can be used to determine the best number of\n",
    "clusters for the dataset at hand. All in all, k-means is pretty efficient both in time and\n",
    "complexity, however it does not perform very well with non-convex clusters, or with data having varying shapes\n",
    "and densities. One possible way to deal with some of these\n",
    "issues is by increasing the value of k, and later recombining\n",
    "the sub-clusters obtained. Also, remember that k-means\n",
    "requires a carefully chosen distance measure that captures\n",
    "the properties of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 K-Means in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wine = pd.read_csv(\"Data/wine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['Wine', 'Alcohol', 'Malic.acid', 'Ash', 'Acl', 'Mg', 'Phenols',\n       'Flavanoids', 'Nonflavanoid.phenols', 'Proanth', 'Color.int', 'Hue',\n       'OD', 'Proline'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "wine.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = wine[['Alcohol','Color.int']].values\n",
    "Y = wine['Wine'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n    n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n    random_state=None, tol=0.0001, verbose=0)"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "from sklearn import cluster\n",
    "cls_wine = cluster.KMeans(n_clusters=3)\n",
    "cls_wine.fit(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1 1 1 2 1 1 1 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n 1 0 1 1 1 1 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 1 0\n 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 2 0 1 1 1 1 1 1 1 2 1 1 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 2 1 2 2 2 2 2 2 2]\n"
    }
   ],
   "source": [
    "print(cls_wine.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[12.25353846  2.854     ]\n [13.45168831  5.19441558]\n [13.38472222  8.74611108]]\n"
    }
   ],
   "source": [
    "print(cls_wine.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.5097267872581326\n"
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "print(silhouette_score(X1,cls_wine.labels_))"
   ]
  }
 ]
}